{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c593e910",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Install required text processing libraries for the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dff1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dc3c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89f39d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c3a4f",
   "metadata": {},
   "source": [
    "## 2. Creating Text Representations\n",
    "\n",
    "Text data needs to be converted to numeric representations before they can be used to train deep learning models. The Spam classification feature data is converted to TF-IDF vectors and the target variable is converted to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08900f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Data :\n",
      "------------------------------------\n",
      "          CLASS                               MESSAGE\n",
      "0  company_info         What is Handyman Prosthetics?\n",
      "1  company_info                     What is Handyman?\n",
      "2  company_info                Tell me about Handyman\n",
      "3  company_info    Tell me about handyman prosthetics\n",
      "4  company_info  Hi Handy. Tell me about your company\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "import pickle\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "#Load chat Data and review content\n",
    "chat_data = pd.read_csv(\"chats.csv\")\n",
    "\n",
    "print(\"\\nLoaded Data :\\n------------------------------------\")\n",
    "print(chat_data.head())\n",
    "\n",
    "#Separate feature and target data\n",
    "chat_classes_raw = chat_data[\"CLASS\"]\n",
    "chat_messages = chat_data[\"MESSAGE\"]\n",
    "num_classes = chat_classes_raw.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64202dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vssashar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape :  (451, 73)\n",
      "One-hot Encoding Shape :  (451, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Custom tokenizer to remove stopwords and use lemmatization\n",
    "def customtokenize(str):\n",
    "    #Split string as tokens\n",
    "    tokens=nltk.word_tokenize(str)\n",
    "    #Filter for stopwords\n",
    "    nostop = list(filter(lambda token: token not in stopwords.words('english'), tokens))\n",
    "    #Perform lemmatization\n",
    "    lemmatized=[lemmatizer.lemmatize(word) for word in nostop ]\n",
    "    return lemmatized\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Build a TF-IDF Vectorizer model\n",
    "vectorizer = TfidfVectorizer(tokenizer=customtokenize)\n",
    "\n",
    "#Transform feature input to TF-IDF\n",
    "tfidf=vectorizer.fit_transform(chat_messages)\n",
    "pickle.dump( vectorizer, open( \"bot_vectorizer.p\", \"wb\" ) )\n",
    "\n",
    "#Convert TF-IDF to numpy array\n",
    "tfidf_array = tfidf.toarray()\n",
    "\n",
    "#Build a label encoder for target variable to convert strings to numeric values.\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "chat_classes = label_encoder.fit_transform(\n",
    "                                chat_classes_raw)\n",
    "\n",
    "np.save('bot_label_encoder.npy', label_encoder.classes_)\n",
    "#Convert target to one-hot encoding vector\n",
    "chat_classes = tf.keras.utils.to_categorical(chat_classes,num_classes)\n",
    "\n",
    "print(\"TF-IDF Matrix Shape : \", tfidf.shape)\n",
    "print(\"One-hot Encoding Shape : \", chat_classes.shape)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split( tfidf_array, chat_classes, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a983f",
   "metadata": {},
   "source": [
    "## 3. Building and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d927db5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden-Layer-1 (Dense)      (None, 32)                2368      \n",
      "                                                                 \n",
      " Hidden-Layer-2 (Dense)      (None, 32)                1056      \n",
      "                                                                 \n",
      " Hidden-Layer-3 (Dense)      (None, 32)                1056      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,711\n",
      "Trainable params: 4,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Setup Hyper Parameters for building the model\n",
    "NB_CLASSES=num_classes\n",
    "N_HIDDEN=32\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                             input_shape=(X_train.shape[1],),\n",
    "                              name='Hidden-Layer-1',\n",
    "                              activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                              name='Hidden-Layer-2',\n",
    "                              activation='relu'))\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                              name='Hidden-Layer-3',\n",
    "                              activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "                             name='Output-Layer',\n",
    "                             activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "294ceb7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Progress:\n",
      "------------------------------------\n",
      "Epoch 1/30\n",
      "41/41 [==============================] - 1s 5ms/step - loss: 1.7854 - accuracy: 0.3981 - val_loss: 1.5891 - val_accuracy: 0.5432\n",
      "Epoch 2/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 1.5077 - accuracy: 0.4259 - val_loss: 1.3269 - val_accuracy: 0.5062\n",
      "Epoch 3/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 1.3312 - accuracy: 0.4722 - val_loss: 1.1819 - val_accuracy: 0.6790\n",
      "Epoch 4/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 1.1470 - accuracy: 0.6605 - val_loss: 1.0085 - val_accuracy: 0.7654\n",
      "Epoch 5/30\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.9305 - accuracy: 0.7315 - val_loss: 0.8045 - val_accuracy: 0.7778\n",
      "Epoch 6/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.7461 - accuracy: 0.7346 - val_loss: 0.7049 - val_accuracy: 0.7901\n",
      "Epoch 7/30\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.7531 - val_loss: 0.5459 - val_accuracy: 0.8272\n",
      "Epoch 8/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8148 - val_loss: 0.4522 - val_accuracy: 0.8642\n",
      "Epoch 9/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8920 - val_loss: 0.3969 - val_accuracy: 0.9136\n",
      "Epoch 10/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.9167 - val_loss: 0.3510 - val_accuracy: 0.9259\n",
      "Epoch 11/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.9321 - val_loss: 0.3100 - val_accuracy: 0.9259\n",
      "Epoch 12/30\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9475 - val_loss: 0.2720 - val_accuracy: 0.9383\n",
      "Epoch 13/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9599 - val_loss: 0.2392 - val_accuracy: 0.9383\n",
      "Epoch 14/30\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9691 - val_loss: 0.2146 - val_accuracy: 0.9506\n",
      "Epoch 15/30\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9846 - val_loss: 0.1959 - val_accuracy: 0.9506\n",
      "Epoch 16/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9815 - val_loss: 0.1839 - val_accuracy: 0.9506\n",
      "Epoch 17/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9877 - val_loss: 0.1561 - val_accuracy: 0.9506\n",
      "Epoch 18/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9877 - val_loss: 0.1327 - val_accuracy: 0.9630\n",
      "Epoch 19/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9846 - val_loss: 0.1209 - val_accuracy: 0.9630\n",
      "Epoch 20/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9907 - val_loss: 0.1114 - val_accuracy: 0.9630\n",
      "Epoch 21/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9938 - val_loss: 0.0969 - val_accuracy: 0.9753\n",
      "Epoch 22/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9907 - val_loss: 0.1041 - val_accuracy: 0.9630\n",
      "Epoch 23/30\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9877 - val_loss: 0.1121 - val_accuracy: 0.9630\n",
      "Epoch 24/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9938 - val_loss: 0.0929 - val_accuracy: 0.9753\n",
      "Epoch 25/30\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9938 - val_loss: 0.0934 - val_accuracy: 0.9753\n",
      "Epoch 26/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9938 - val_loss: 0.0827 - val_accuracy: 0.9753\n",
      "Epoch 27/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9907 - val_loss: 0.0717 - val_accuracy: 0.9877\n",
      "Epoch 28/30\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9907 - val_loss: 0.0755 - val_accuracy: 0.9753\n",
      "Epoch 29/30\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9907 - val_loss: 0.0777 - val_accuracy: 0.9877\n",
      "Epoch 30/30\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0642 - val_accuracy: 0.9877\n",
      "\n",
      "Accuracy during Training :\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation against Test Dataset :\n",
      "------------------------------------\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01716342382133007, 1.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make it verbose so we can see the progress\n",
    "VERBOSE=1\n",
    "\n",
    "#Setup Hyper Parameters for training\n",
    "BATCH_SIZE=8\n",
    "EPOCHS=30\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "print(\"\\nTraining Progress:\\n------------------------------------\")\n",
    "\n",
    "history=model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "print(\"\\nAccuracy during Training :\\n------------------------------------\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history)[\"accuracy\"].plot(figsize=(8, 5))\n",
    "plt.title(\"Accuracy improvements with Epoch\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0cb0b9",
   "metadata": {},
   "source": [
    "## 4. Saving and Loading Models\n",
    "\n",
    "The training and inference environments are usually separate. Models need to be saved after they are validated. They are then loaded into the inference environments for actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76230ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Hidden-Layer-1_input with unsupported characters which will be renamed to hidden_layer_1_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: chatbot_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: chatbot_model\\assets\n"
     ]
    }
   ],
   "source": [
    "#Saving a model\n",
    "    \n",
    "model.save(\"chatbot_model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "983f46c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden-Layer-1 (Dense)      (None, 32)                2368      \n",
      "                                                                 \n",
      " Hidden-Layer-2 (Dense)      (None, 32)                1056      \n",
      "                                                                 \n",
      " Hidden-Layer-3 (Dense)      (None, 32)                1056      \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,711\n",
      "Trainable params: 4,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Loading a Model \n",
    "loaded_model = keras.models.load_model(\"chatbot_model\")\n",
    "\n",
    "#Print Model Summary\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae92a0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['all_products', 'buy_request', 'company_info', 'demo_request',\n",
       "       'end_convo', 'exoskeleton_product', 'prosthesis_products'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9d4714",
   "metadata": {},
   "source": [
    "## 5. Predicting for Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51a495d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vssashar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import preprocessing\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb0bdcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "Prediction Output: [6 3 4 4]\n",
      "Prediction Classes are  ['prosthesis_products' 'demo_request' 'end_convo' 'end_convo']\n"
     ]
    }
   ],
   "source": [
    "#Predict for multiple samples using batch processing\n",
    "#Custom tokenizer to remove stopwords and use lemmatization\n",
    "def customtokenize(str):\n",
    "    #Split string as tokens\n",
    "    tokens=nltk.word_tokenize(str)\n",
    "    #Filter for stopwords\n",
    "    nostop = list(filter(lambda token: token not in stopwords.words('english'), tokens))\n",
    "    #Perform lemmatization\n",
    "    lemmatized=[lemmatizer.lemmatize(word) for word in nostop ]\n",
    "    return lemmatized\n",
    "\n",
    "#Convert input into IF-IDF vector using the same vectorizer model\n",
    "vectorizer = pickle.load( open( \"bot_vectorizer.p\", \"rb\" ) );\n",
    "predict_tfidf=vectorizer.transform([\"tell me about hand prosthetics\",\n",
    "                                    \"how does your product work\",\"Not needed\",\"Thank you\"]).toarray();\n",
    "\n",
    "# print(predict_tfidf.shape)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder();\n",
    "encoder.classes_ = np.load('bot_label_encoder.npy',allow_pickle=True);\n",
    "# print(encoder.classes_)\n",
    "#Predict using model\n",
    "prediction=np.argmax( loaded_model.predict(predict_tfidf), axis=1 );\n",
    "\n",
    "# print('Prediction metrics: ',loaded_model.predict(predict_tfidf))\n",
    "print(\"Prediction Output:\" , prediction);\n",
    "\n",
    "#Print prediction classes\n",
    "print(\"Prediction Classes are \", encoder.inverse_transform(prediction));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e2350",
   "metadata": {},
   "source": [
    "## 6. Loading replies\n",
    "Replies need to be saved into \"bot_replies\" folder with names as <bot_message_class>.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "899e4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_reply_classes = ['start_convo']+list(encoder.classes_) \n",
    "bot_replies = {}\n",
    "for reply_class in bot_reply_classes:\n",
    "    with open('bot_replies/'+reply_class+'.txt') as f:\n",
    "        bot_replies[reply_class] = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9b0c72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_convo:\n",
      "Hi! I am Handy, AI chatbot of Handyman Prosthetics. How may I help you?\n",
      "_____________\n",
      "all_products:\n",
      "Here's our complete catalogue:\n",
      "MARK I: For arm amputees. Our simple and light weight model of arm prosthesis. Suitable for simple tasks.\n",
      "MARK II: For arm amputees. An advanced and dextrous arm. Involves softroboric for best grip and individual finger control.\n",
      "EXO 0: For hand injury rehabilitation and hand paralysis. Comfortable, light-weight and simple.\n",
      "EXO I: For hand injury rehabilitation and hand paralysis. Dextrous movements and powerful gripping action.\n",
      "_____________\n",
      "buy_request:\n",
      "Prosthesis is a very personalized solution, differening from user to user.\n",
      "Kindly provide your details here and we will contact you:\n",
      "https://forms.gle/C6Em8mSkH5zgbS576\n",
      "_____________\n",
      "company_info:\n",
      "Handyman Prosthetics create hand prosthesis and exoskeleton support for people who lost their arms or the ability to control it.\n",
      "Our perosonalized solutions enable them to carry out simple day to day tasks without having to rely on others.\n",
      "_____________\n",
      "demo_request:\n",
      "Sure! Here's a video demo:\n",
      "https://youtube.com/playlist?list=PLsE-jsMAf6MONnhrq0_Z4-rIY8xSVyArC\n",
      "_____________\n",
      "end_convo:\n",
      "Thank you for contacting us. Have a nice day!\n",
      "_____________\n",
      "exoskeleton_product:\n",
      "Here are our exoskeleton support solutions:\n",
      "EXO 0: For hand injury rehabilitation and hand paralysis. Comfortable, light-weight and simple.\n",
      "EXO I: For hand injury rehabilitation and hand paralysis. Dextrous movements and powerful gripping action.\n",
      "_____________\n",
      "prosthesis_products:\n",
      "Here are our arm prosthesis solutions:\n",
      "MARK I: For arm amputees. Our simple and light weight model of arm prosthesis. Suitable for simple tasks.\n",
      "MARK II: For arm amputees. An advanced and dextrous arm. Involves softroboric for best grip and individual finger control.\n",
      "_____________\n"
     ]
    }
   ],
   "source": [
    "for reply_class in bot_reply_classes:\n",
    "\n",
    "    print(reply_class+':')\n",
    "    for line in bot_replies[reply_class]:\n",
    "        print(line.strip())\n",
    "    print(\"_____________\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9445fe",
   "metadata": {},
   "source": [
    "## 7. Chatbot in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f6da9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handy: Hi! I am Handy, AI chatbot of Handyman Prosthetics. How may I help you?\n",
      "user: Hi Handy. Tell me about your company\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Handy: Handyman Prosthetics create hand prosthesis and exoskeleton support for people who lost their arms or the ability to control it.\n",
      "Handy: Our perosonalized solutions enable them to carry out simple day to day tasks without having to rely on others.\n",
      "user: Nice. Tell me about all your products\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Handy: Here's our complete catalogue:\n",
      "Handy: MARK I: For arm amputees. Our simple and light weight model of arm prosthesis. Suitable for simple tasks.\n",
      "Handy: MARK II: For arm amputees. An advanced and dextrous arm. Involves softroboric for best grip and individual finger control.\n",
      "Handy: EXO 0: For hand injury rehabilitation and hand paralysis. Comfortable, light-weight and simple.\n",
      "Handy: EXO I: For hand injury rehabilitation and hand paralysis. Dextrous movements and powerful gripping action.\n",
      "user: Suggest solutions for hand amputees\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Handy: Here are our arm prosthesis solutions:\n",
      "Handy: MARK I: For arm amputees. Our simple and light weight model of arm prosthesis. Suitable for simple tasks.\n",
      "Handy: MARK II: For arm amputees. An advanced and dextrous arm. Involves softroboric for best grip and individual finger control.\n",
      "user: can i get a demo?\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Handy: Sure! Here's a video demo:\n",
      "Handy: https://youtube.com/playlist?list=PLsE-jsMAf6MONnhrq0_Z4-rIY8xSVyArC\n",
      "user: I would like to buy Exo0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Handy: Prosthesis is a very personalized solution, differening from user to user.\n",
      "Handy: Kindly provide your details here and we will contact you:\n",
      "Handy: https://forms.gle/C6Em8mSkH5zgbS576\n",
      "user: Ok. Thank you\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Thank you for contacting us. Have a nice day!\n"
     ]
    }
   ],
   "source": [
    "start_state = 'start_convo'\n",
    "end_state = 'end_convo'\n",
    "\n",
    "state = start_state\n",
    "while state!=end_state:\n",
    "    for line in bot_replies[state]:\n",
    "        print('Handy: '+line.strip())\n",
    "        \n",
    "    user_reply = input('user: ')\n",
    "    \n",
    "    predict_tfidf=vectorizer.transform([user_reply]).toarray();\n",
    "    prediction=np.argmax( loaded_model.predict(predict_tfidf), axis=1 );\n",
    "    \n",
    "    state = encoder.inverse_transform(prediction)[0]\n",
    "#     print(state)\n",
    "for line in bot_replies[state]:\n",
    "    print('Handy: '+line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afedaee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
